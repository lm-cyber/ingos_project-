# README: Synthetic Data Generator and Fine-Tuning CRAFT with SegFormer

## Проект: Генератор синтетических данных и дообучение CRAFT с SegFormer

### Описание проекта
В рамках этого учебного проекта студенты создадут генератор синтетических данных для задачи детекции текста на изображениях, используя модель **CRAFT (Character-Region Awareness For Text Detection)**. Затем, на основе созданных данных, будет выполнено fine-tuning модели CRAFT с использованием **SegFormer** в качестве её бэкбона.

### Цели проекта
1. Разработать генератор синтетических данных, который будет создавать аннотированные изображения для обучения.
2. Использовать созданные данные для дообучения модели CRAFT с SegFormer в качестве бэкбона.
3. Провести анализ качества дообученной модели на тестовых данных.

### Основные этапы

#### 1. Разработка генератора синтетических данных
- **Функционал генератора**:
  - Генерация изображений с текстом различной сложности (шрифты, размеры, повороты, искажения).
  - Добавление реалистичных фонов (например, текстуры улиц, документов, плакатов).
  - Создание аннотаций в формате, совместимом с CRAFT (например, полигональные разметки текстовых регионов).
- **Ключевые библиотеки**: Python, OpenCV, PIL, NumPy.

#### 2. Fine-tuning модели CRAFT с использованием SegFormer
- **Подготовка данных**:
  - Разделение данных на тренировочный, валидационный и тестовый наборы.
  - Проверка качества аннотаций и данных.
- **Модификация CRAFT**:
  - Замена стандартного бэкбона CRAFT на SegFormer.
  - Настройка параметров обучения (оптимизатор, lr scheduler, метрики).
- **Обучение модели**:
  - Использование фреймворков PyTorch/Transformers для реализации fine-tuning.
  - Мониторинг метрик качества на валидационных данных.

#### 3. Оценка результатов
- **Тестирование модели**:
  - Проверка качества работы модели на синтетических и реальных данных.
  - Сравнение метрик до и после дообучения.
- **Визуализация результатов**:
  - Примеры предсказаний модели на тестовых изображениях.
  - Сравнение детекций с ground truth.

### Требования к окружению
- Python >= 3.8
- PyTorch >= 1.10
- OpenCV
- NumPy
- Transformers
- Albumentations (для аугментаций)
- PIL (Pillow)

### Структура проекта
```
project/
|-- data/                   # Данные (сгенерированные изображения и аннотации)
|-- generator/              # Код генератора синтетических данных
|   |-- __init__.py         # Инициализация
|   |-- generator.py        # Основной код генератора
|-- models/                 # Модель и скрипты для обучения
|   |-- craft_segformer.py  # Модифицированная CRAFT с SegFormer
|   |-- train.py            # Скрипт для обучения модели
|   |-- utils.py            # Утилиты для работы с данными и метриками
|-- notebooks/              # Jupyter Notebooks для анализа
|-- README.md               # Описание проекта
|-- requirements.txt        # Зависимости
```

### Как запустить проект
1. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```
2. Запустите генерацию синтетических данных:
   ```bash
   python generator/generator.py
   ```
3. Выполните обучение модели:
   ```bash
   python models/train.py
   ```
4. Проверьте результаты модели на тестовых данных:
   ```bash
   python models/evaluate.py
   ```

### Метрики качества
- **IoU (Intersection over Union)** для оценки качества детекции регионов.
- **F1-Score** для текстовых регионов (на основе Precision и Recall).
- **Loss** (Cross-Entropy, MSE) для мониторинга процесса обучения.

### Ресурсы и полезные ссылки
- Оригинальная статья CRAFT: [CRAFT Paper](https://arxiv.org/abs/1904.01941)
- Описание SegFormer: [SegFormer Paper](https://arxiv.org/abs/2105.15203)
- Открытые датасеты для задач детекции текста:
  - SynthText ([GitHub](https://github.com/ankush-me/SynthText))
  - ICDAR ([ICDAR Website](https://rrc.cvc.uab.es/))

### Советы и рекомендации
- Тщательно тестируйте генератор данных, чтобы обеспечить разнообразие и реалистичность.
- Экспериментируйте с параметрами модели, чтобы добиться лучшей производительности.
- Документируйте каждый этап работы для упрощения анализа и воспроизведения результатов.

